# version: v3.4.0

# context defines the context of this Desired State File.
# It is used to allow Helmsman identify which releases are managed by which DSF.
# Therefore, it is important that each DSF uses a unique context.
context: aruba # defaults to "default" if not provided

# metadata -- add as many key/value pairs as you want
metadata:
  owner: krzwiatrzyk

# paths to the certificate for connecting to the cluster
# You can skip this if you use Helmsman on a machine with kubectl already connected to your k8s cluster.
# you have to use exact key names here : 'caCrt' for certificate and 'caKey' for the key and caClient for the client certificate
# certificates:
#caClient: "gs://mybucket/client.crt" # GCS bucket path
#caCrt: "s3://mybucket/ca.crt" # S3 bucket path
#caKey: "../ca.key" # valid local file relative path

settings:
  kubeContext: "default" # will try connect to this context first, if it does not exist, it will be created using the details below
  #username: "admin"
  #password: "$K8S_PASSWORD" # the name of an environment variable containing the k8s password
  #clusterURI: "$SET_URI" # the name of an environment variable containing the cluster API
  #clusterURI: "https://192.168.99.100:8443" # equivalent to the above
  #storageBackend: "secret"
  #slackWebhook:  "$slack" # or your slack webhook url
  #reverseDelete: false # reverse the priorities on delete
  #### to use bearer token:
  #  bearerToken: true
  #  clusterURI: "https://kubernetes.default"
  # globalHooks:
  #   successCondition: "Initialized"
  #   deleteOnSuccess: true
  #   postInstall: "job.yaml"
  globalMaxHistory: 5

# define your environments and their k8s namespaces
namespaces:
  apps:
    protected: false
    limits:
      - type: Container
        default:
          cpu: "300m"
          memory: "200Mi"
        defaultRequest:
          cpu: "200m"
          memory: "100Mi"
      - type: Pod
        max:
          memory: "300Mi"
    # labels:
    #   env: "staging"
    # quotas:
    #   limits.cpu: "10"
    #   limits.memory: "20Gi"
    #   pods: 25
    #   requests.cpu: "10"
    #   requests.memory: "30Gi"
    #   customQuotas:
    #     - name: "requests.nvidia.com/gpu"
    #       value: "2"


# define any private/public helm charts repos you would like to get charts from
# syntax: repo_name: "repo_url"
# only private repos hosted in s3 buckets are now supported
helmRepos:
  traefik: https://helm.traefik.io/traefik

# define the desired state of your applications helm charts
# each contains the following:

apps:
  customchart:
    namespace: "apps"
    enabled: true
    chart: "./CustomChart"
    version: 0.0.1
  traefik:
    namespace: "apps" # maps to the namespace as defined in namespaces above
    enabled: true # change to false if you want to delete this app release empty: false:
    chart: "traefik/traefik" # changing the chart name means delete and recreate this chart
    version: "10.14.2" # chart version
    ### Optional values below
    valuesFiles:
    - values/traefik.yaml
    #test: false
    #priority: -2
    #noHooks: false
    #timeout: 300
    #maxHistory: 4
    # additional helm flags for this release
    #helmFlags:
    #  - "--devel"
    #protected: true
    #wait: true
    #hooks:
    #  successCondition: "Complete"
    #  successTimeout: "90s"
    #  deleteOnSuccess: true
    #  preInstall: "job.yaml"
    #   preInstall: "https://github.com/jetstack/cert-manager/releases/download/v0.14.0/cert-manager.crds.yaml"
    #   postInstall: "https://raw.githubusercontent.com/jetstack/cert-manager/release-0.14/deploy/manifests/00-crds.yaml"
    #   postInstall: "job.yaml"
    #   preUpgrade: "job.yaml"
    #   postUpgrade: "job.yaml"
    #   preDelete: "job.yaml"
    #   postDelete: "job.yaml"
    #set:
    #  "images.tag": $$TAG # $$ is escaped and $TAG is passed literally to images.tag (no env variable expansion)
